<html>
<head>
<title>Junxiang Li Homepage</title>
<meta http-equiv="Content Type" content="text/html" charset="UTF-8" />
<link rel="stylesheet" type="text/css" href="doc/theme.css">
<script async src="./files/analytics.js"></script>
</head>

<body>
<div id="layout-content" style="margin-top:25px; margin-bottom:25px;">

<table width="100%" border="0" align="center">
    <tr>
    <td width="5%"></td>
    <td width="60%">
        <div id="header" style="float:left">
        <h1>Junxiang Li（李峻翔）</h1>
        <p> Associate Professor</p>
        <p> College of Intelligence Science and Technology, National University of Defense Technology (NUDT)</p>
        <p> <em> Email: enginelee@yeah.net </em> </p>
        <!--
<p> <a href="https://scholar.google.com/citations?user=08U8joq2FOQC&hl=zh-CN" target="_blank"><img src="./pic/gs.png" height="30px" style="margin-bottom:-3px"></a>-->
        <a href="https://www.researchgate.net/profile/Li-Junxiang" target="_blank"><img src="./pic/researchgate.png" height="30px" style="margin-bottom:-3px"></a>
        <a href="https://github.com/junxiang-li" target="_blank"><img src="./pic/github.png" height="30px" style="margin-bottom:-3px"></a>
    </p>

    </div>
    </td>
    <td width="30%">
        <div id="photo" style="float:right;">
        <img src="./pic/photo_ljx.jpg" alt="my photo" style="width:219px;height:317px;">
        </div>
    </td>
    <td width="5%"></td>
    </tr>
</table>


<table width = "100%" border="0" align="center">
    <tr>
    <td width="5%"></td>
    <td width="90%">
        <hr>
        <div id="bio" class="contents">
        <h2>简介 Biography <!-- <a href="./doc/cv-2022.pdf" target="_blank">[CV]</a> --></h2>
            <p>I am currently an Associate Professor in the College of Intelligence Science and Technology, <a href="https://www.nudt.edu.cn/" target="_blank"> National University of Defense Technology (NUDT)</a>.</p>
        <p> My research focuses on intelligent transportation system, air-ground collaborative unmanned system, intelligent decision-making and planning.</p>
        <hr></div>
    </td>
    <td width="5%" align="left">
    </tr>


<!-- *******************************************************************************************************************-->
<tr>
<td width="5%"></td>
<td width="90%">
    <div id="divPersonalAppointmentAward" class="contents">
    <h2> 个人经历 Personal Appointment and Award </h2>
    <br><table id="divPersonalAppointmentAward" border="0" width="100%">
        <tbody>
            <tr>
                <td> * 2024-至今(Now):控制科学与工程（学术）/电子信息（应用）学科硕士研究生导师；</td>
            </tr>
            <tr>
                <td> * 2021-至今(Now):担任教研室副主任 (Deputy Director of Teaching and Research Office)；</td>
            </tr>
            <tr>
                <td> * 2021: 赴北京某科研机构从事科研论证工作；</td>
            </tr>
            <tr>
                <td> * 2019: 获得国防科技大学控制科学与工程专业博士学位( Ph.D. in Engineering, in NUDT)；</td>
            </tr>
            <tr>
                <td> * 2015-2016: 国家留学基金委（CSC）公派留学新西兰Massey University进行联合培养，就读计算机科学专业(studied in Massey University, New Zealand funded by China Scholarship Council (CSC), majoring in computer science)</td>
            </tr>
            <tr>
                <td> * 荣立三等功一次，嘉奖六次，被评为“优秀共产党员”，“四有人员”两次。</td>
            </tr>
        </tbody>
    </table>
    <hr></div>
</td>
<td width="5%"></td>
</tr>
    <!-- *******************************************************************************************************************-->


    <!-- *******************************************************************************************************************-->
<tr>
<td width="5%"></td>
<td width="90%">
    <div id="divProfessionalService" class="contents">
    <h2> 学术任职 Professional Service </h2>
    <br><table id="divProfessionalService" border="0" width="100%">
        <tbody>
            <tr>
                <td> [1] 担任中国图象图形学学会视觉感知智能系统专委会委员，中国人工智能学会和自动化学会会员。<br>
<li>Commitee Member：     Committee of Visual Perception Intelligent System of Chinese Society of Image and Graphics<br>
<li>Member：     Chinese Society of Artificial Intelligence, Chinese Society of Automation</td>
            </tr>
            <tr>
                <td> [2] 担任《无人系统技术》青年编委（2024-2025）<br>
<li> Served as a young editorial board member for "Unmanned Systems Technology" (2024-2025) </td>
            </tr>
            <tr>
                <td> [3] 担任本领域 IEEE Transactions on Intelligent Vehicle, IEEE Transactions on Intelligent Transportation Systems, IEEE Transactions on Vehicular Technology 等期刊（均为中国科协高质量科技期刊 A 类）审稿人。<br>
<li>Reviewer：     IEEE Transactions on Intelligent Vehicle, IEEE Transactions on Intelligent Transportation Systems, IEEE Transactions on Vehicular Technology</td>
            </tr>
             <tr>
                <td> [4] 担任机器人领域国际顶级会议IEEE / RSJ International Conference on Intelligent Robots and Systems (IROS) 2024 Associate Editor。
<li>Associate Editor：  IEEE / RSJ International Conference on Intelligent Robots and Systems (IROS) 2024</td>
            </tr>
        </tbody>
    </table>
    <hr></div>
</td>
<td width="5%"></td>
</tr>
    <!-- *******************************************************************************************************************-->
    
<!-- *******************************************************************************************************************-->
    <tr>
    <td width="5%"></td>
    <td width="90%">
        <div id="pub" class="contents">
        <h2> 发表论文 Published Articles（Selected） <a href="https://www.researchgate.net/profile/Li-Junxiang" target="_blank">[ResearchGate]</a></h2>
    <br><span>&#8224</span> indicates equal contribution, and * indicates corresponding authorship.<br>
<li>[1] <b>Junxiang Li</b>, Liang Yao, Xin Xu, Bang Cheng, Junkai Ren. Deep reinforcement learning for pedestrian collision avoidance and human-machine cooperative driving[J]. Information Sciences (IS), 2020, 532: 110-124. (SCI, IF 2023: 8.1, JCR Q1, ranks top 10% in Computer Science, Information Systems field,自动化学会A类期刊,中国兵工学会T1类期刊)
<li>[2] <b>Junxiang Li</b>, Bin Dai, Xiaohui Li, Ruili Wang, Xin Xu, Bohan Jiang, Yi Di. An Interaction-aware Predictive Motion Planner for Unmanned Ground Vehicles in Dynamic Street Scenarios[J]. International Journal of Robotics and Automation (IJRA), 2019, 34(3). (SCI, IF 2023：0.9)
<li>[3] <b>Junxiang Li</b>, Bin Dai, Xiaohui Li, Xin Xu, Daxue Liu. A Dynamic Bayesian Network for Vehicle Maneuver Prediction in Highway Driving Scenarios: Framework and Verification [J]. Electronics, 2019, 8(1):40. (SCI，IF 2023：2.9, JCR 分区工程技术类二区)
<li>[4] Yichuan Zhang, Yixing Lan, Qiang Fang, Xin Xu, <b>Junxiang Li</b>, Yujun Zeng. Efficient Reinforcement Learning from Demonstration via Bayesian Network-Based Knowledge Extraction. Computational Intelligence and Neuroscience (CIN), vol. 2021, 16 pages, 2021. (SCI, IF 2021: 3.633, JCR Q2)
<li>[5] Ou, Wenxiao, Tao Wu, <b>Junxiang Li</b>, Jinjiang Xu, and Bowen Li. 2022. "RREV: A Robust and Reliable End-to-End Visual Navigation" Drones 6, no. 11: 344. (SCI, 控制科学与工程、电子信息学科高水平期刊)
<li>[6] Yichuan Zhang, Junkai Ren, <b>Junxiang Li</b>, Qiang Fang, Xin Xu. Deep Q-learning with Explainable and Transferable Domain Rules[C]// 2021 17th International Conference on Intelligent Computing (ICIC). 2021:(8)12-15.(EI)
<li>[7] Lina Qin, Aihua Yang, <b>Junxiang Li</b>*, Yanlin Li, Yu feng, Liu Liu. Review and outlook of decision-making methods in Unmanned Ground Vehicles[C]// 2021 International Conference on Autonomous Unmanned Systems (ICAUS 2021). 2021: 9(24-26).(EI,自动化学会推荐 C 类会议)
<li>[8] Liang Yao, <b>Junxiang Li</b>*, Bohan Jiang , et al. Model-based trajectory prediction approach using an improved dynamic window approach and an interactive behavior model[C]//2019 IEEE International Conference on Unmanned Systems (ICUS). IEEE, 2019: 457-462.(EI,自动化学会推荐 B 类会议)
<li>[9] <b>Junxiang Li</b>, Li X, Jiang B, et al. A maneuver-prediction method based on dynamic Bayesian network in highway scenarios[C]//2018 Chinese Control And Decision Conference (CCDC). IEEE, 2018: 3392-3397.(EI, 自动化学会推荐 A 类会议)
<li>[10] <b>Junxiang Li</b>, Li C, Sun Z, et al. A real-time motion planner for intelligent vehicles based on a fast SSTG method[C]//2018 37th Chinese Control Conference (CCC). IEEE, 2018: 5509-5513.(EI, 自动化学会推荐 A 类会议)
<li>[11] <b>Junxiang Li</b>, Dai B, Liu D, et al. An optimal sampling-based path planning under uncertainty based on linear quadratic regulator[C]//2017 2nd International Conference on Robotics and Automation Engineering (ICRAE). IEEE, 2017: 84-88.(EI)
<li>[12] Y. Xiao, X. Zhang, X. Xu, Y. Lu and <b>Junxiang Li</b>, "DDK: A Deep Koopman Approach for Longitudinal and Lateral Control of Autonomous Ground Vehicles," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 975-981, doi: 10.1109/ICRA48891.2023.10161104.(EI, 自动化学会推荐 A 类会议)
<li>[13] <b>Junxiang Li</b>, Dai B, Li X, et al. A real-time and predictive trajectory-generation motion planner for autonomous ground vehicles[C]//2017 9th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC). IEEE, 2017, 2: 108-113.(EI)
        <hr></div>
    </td>
    <td width="5%" align="left">
    </tr>
        <!-- *******************************************************************************************************************-->

    <!-- *******************************************************************************************************************-->
    <tr>
    <td width="5%"></td>
    <td width="90%">
        <div id="patents" class="contents">
        <h2> 专利/软著 Patents / Software copyrights </a></h2><br>
  <li>  [1] <b>李峻翔</b>，李晓辉，孙振平，刘大学，叶磊，史美萍，吴涛.一种高泛化能力的交互车辆驾驶意图预测方法和装置，ZL202111544865.0.
  <li> [2] 刘大学，<b>李峻翔</b>，吴涛，史美萍. 基于注意力机制的无人车多分辨率视频生成方法和装置, ZL202111144966.9.
  <li>  [3] 刘大学，史美萍，<b>李峻翔</b>. 一种等高线引导线的自主车三维路径规划方法， CN117724489A.
  <li> [4] <b>李峻翔</b>，刘泽钰，孙振平，刘大学，李晓辉.空地无人集群协同任务规划软件 V1.0. 2024SR0130644.
  <li>  [5] <b>李峻翔</b>，张云涛，吴涛，李健，付浩.空地无人集群任务临机调整软件V1.0. 2024SR0029162.
        <hr></div>
    </td>
    <td width="5%" align="left">
    </tr>
        <!-- *******************************************************************************************************************-->
    
    
<!-- *******************************************************************************************************************-->
    <tr>
    <td width="5%"></td>
    <td width="90%">
        <div id="ResearchFundings" class="contents">
        <h2>科研项目情况 Research Fundings</h2>
<br>
<b>主持项目 Host：</b><br>

<li>[1] 陆军××部，×××项目，×××，有人/无人×××协同技术，2023/06-2024/12，67.5万元，在研，主持
<li>[2] 陆军××部，×××项目，×××，复杂×××一体化决策规划与控制技术，2023/06-2024/12，62万元，在研，主持
<li>[3] 国防科技大学智能科学学院，青年骨干教师培养计划，2022/06-2025/06，30万元，在研，主持
<li>[4] 国家自然科学基金委员会，青年基金项目，62103431，动态开放环境下基于交互分析与语义推理的无人车决策技术研究，2022/01-2024/12，30万元，在研，主持
<li>[5] 军委科技委，×××项目，×××，复杂×××学习型可迁移运动规划方法，2021/10-2024/10，80万元，在研，主持
<li>[6] 国防科技大学，青年创新项目，×××，动态环境下×××决策技术研究，2021/07-2024/06，30万元，在研，主持
<li>[7] 国防科技大学智能科学学院，智能科学学院青年教师创新项目，ZN2019-15，基于交互行为建模的地面无人平台人机协同控制技术研究，2020/01-2022/12，20万元，已结题，主持
<br><br>

<b>部分参与项目 Participant(Selected)：</b><br>
<li>[8] ××部，××项目，×××，智能××架构，2022/12-2025/12，1000万元，在研，参加
<li>[9] 国家自然科学基金委员会，联合基金项目，U21A20518，城市智能客车多模态协同感知与安全高效行驶关键技术研究，2021/06-2024/12，300万元，在研，参加
<li>[10] 军委科技委，×××项目，×××，地面××决策基础问题研究，2019/12-2024/12，2500万元，在研，参加
<li>[11] 国家自然科学基金委员会，杰出青年科学基金项目，61825305，机器人自主控制学习，2019/01-2023/12，400万元，在研，参加
<li>[12] 军委科技委，×××项目，×××，××复杂环境自主导航技术研究，2020/06-2021/12，300万元，已结题，参加
<li>[13] 陆军××部，×××项目，×××，不确定动态环境×××技术，2019/01-2020/12，75万元，已结题，参加
国家自然科学基金委员会，联合基金项目，U1564214，智能汽车人机交互机理与人机共驾技术，2016/01-2019/12，263.6万元，已结题，参加
        <hr></div>
    </td>
    <td width="5%"></td>
    </tr>
<!-- *******************************************************************************************************************-->

<!-- *******************************************************************************************************************-->
    <tr>
    <td width="5%"></td>
    <td width="90%">
        <div id="ResearchApplication" class="contents">
        <h2>成果应用 Research Application </h2>
<br>
本人作为神十三地面无人搜救团队负责人，组织并带领10余人的核心技术团队，利用1个月的时间集中攻关，多方调试，考虑到神十三载人航天搜救任务中地面无人平台参试光学测量搜救时会出现
            1）返回舱体降落点受大气影响，事先无法精确固定，从而地面无人平台缺乏精确引导信息；
            2）现场单位光学拍摄、测量设备众多，网络信号构成复杂电磁环境，导致通信易受到干扰；
            3）航天任务地处戈壁滩地形，该地形上有很多梭梭树和大型植被，地形复杂，可供训练样本稀少。
将本人的研究成果，即非精确引导环境的运动规划技术、基于不确定性建模的迭代自主导航技术、小样本交互行为预测技术，集成到地面无人平台参试光学测量搜救系统中，最终圆满完成了任务，
            被中央电视台CCTV-7，CCTV-13报导为我国首次使用的航天搜救“千里眼”，取得了较大的社会影响。
            相关报道参见：见证航天员回家全过程 全靠航天搜救“千里眼”_新闻频道_中华网 (china.com)、国防科技大学校报报道 (nudt.edu.cn)
             <br> English Version: <br>
As the head of the ground unmanned search and rescue team, I organized and led a core technical team of over 10 people, spending a month focusing on addressing key issues, engaging in multi-party debugging. Our contribution is that the application of ground unmanned vehicle in   the search and rescue missions of air-spacecraft. 
            We faced three main challenges: 1) the landing point of the air-spacecraft is affected by the atmosphere, making it impossible to fix precisely in advance; hence, the ground unmanned platform lacked accurate guidance information; 
            2) numerous optical shooting and measurement equipment, and network signals created a complex electromagnetic environment, making communication vulnerable to interference; 
            and 3) the space mission was located in the Gobi Desert, where the terrain had many spindle trees and large vegetation, posing complex terrain challenges, with limited available training samples. 
            At last, we successfully accomplish the task, which was reported by CCTV CCTV-7 and CCTV-13 as "clairvoyance" in our country's space rescue, achieving great social influence. 
            For more detail, please refer to 见证航天员回家全过程 全靠航天搜救“千里眼”_新闻频道_中华网 (china.com)、国防科技大学校报报道 (nudt.edu.cn) 
        <hr></div>
    </td>
    <td width="5%"></td>
    </tr>
<!-- *******************************************************************************************************************-->


    <!-- *******************************************************************************************************************-->
    <tr>
    <td width="5%"></td>
    <td width="90%">
        <div id="react" class="contents">
        <h2>教学与人才培养 Teaching and Students</h2>
<br>
        目前主讲《图像处理与理解》(Image processing and understanding)、《无人机技术与××演练》等本科生课程2门，
<br>主讲课程被评为校级精品课程(<b>awarded as high-quality courses</b>)，作为MOOC上线的第一门面向全军、聚焦地面无人平台基础技术的课程，突出了“科教融合、聚焦前沿”的特点，获得了较好评价。官网评价分数满分，学员回帖好评率100%。此外，还支撑了全军精品军事职业教育在线课程（本人排名第7）。
            借鉴此次科教融合经验，推广应用到本人负责的本科生课、研究生课与继续教育培训中，累计受益人数超过800余人。
<br> <br>     
<b>课程成长与教学研究 Teaching Research：</b>
<br>    
<li>[1] 李峻翔，刘大学，范一鸣. 军事前沿技术类课程翻转课堂教学实践研究[J].教育教学论坛,2023.04.
<br>
<b>Junxiang Li</b>, Daxue Liu, Yiming Fan. Research on the practice of flipped classroom teaching in military frontier technology courses [J]. Education and Teaching Forum, 2023.04
<li>[2] 李峻翔，牛轶峰，李健，刘大学.新工科背景下综合实践型课程建设研究——以“无人车综合实践”课程为例[C].2021.2021年无人系统高峰论坛(USS 2021)
<br>
<b>Junxiang Li</b>, Yifeng Niu, Jian Li, Daxue Liu. Research on the construction of comprehensive practice courses under the background of new engineering —— Take the "comprehensive practice of unmanned vehicles" course as an example [C].2021.2021 Unmanned Systems Summit Forum (USS 2021)
<li>[3] 校教改课题，新工科背景下综合实践型课程建设研究——以《无人车综合实践》课程为例，主持，2020/12/24-2022/12/31，已结题。
<li>[4] 教材编写（预计2025年出版）

<br> <br>   
       <b>人才培养 Students：</b>
<br>  
<li>本科生Undergraduate students：柯志睛（已读研），付大丽（已毕业），赵舒琪（已读研），刘一骏，王振宇，刘泽钰，张云涛，王子曰
<li>已毕业硕士研究生 Graduate student(Graduated)：王杰，欧文孝，罗少帅
<li>在读硕士研究生 Graduate student：胡彦辰，张鹏年，王程钢
<li>国家级大学生创新项目1项，省级大学生创新项目1项
        <hr></div>
    </td>
    <td width="5%"></td>
    </tr>
<!-- *******************************************************************************************************************-->

<!-- *******************************************************************************************************************-->
    <tr>
    <td width="5%"></td>
    <td width="90%">
        <div id="nrollmentRequirements" class="contents">
        <h2>硕士招生要求 Enrollment requirements  </h2><br>
<li>仅招收中国学生 Only admitting Chinese students
<li>本科毕业自985/211高校，招收专业为控制科学与工程、计算机、自动化等专业。
<li>掌握计算机语言Python、Matlab，并完成过相关开发工作。
<li>熟悉 C、C++语言，使用过Linux系统。参加过无人车、robomaster等竞赛并获奖的同学优先。
<li>熟练运用英语，能够撰写英文学术论文，并用英文进行口头学术交流。发表过二区以上SCI论文优先。<hr></div>
    </td>
    <td width="5%"></td>
    </tr>
<!-- *******************************************************************************************************************-->

    

    <!-- *******************************************************************************************************************-->
    <tr>
    <td width="5%"></td>
    <td width="90">
    <div id="footer">
        <div id="footer-text"></div>
    </div>
        <p><center>
        <br>
            &copy; Junxiang Li | Last updated: Dec 24 2023

          </center></p>
    </div>
    </td>
    <td width="5%"></td>
    </tr>
</body>
</html>
